\section{Implementation and evaluation}\label{sec:experiment}
In this section, an experimental evaluation over three real-life event logs is reported.
The aim of the evaluation is to measure to what extent the forecasted process models/DFGs are capable of correctly reproducing actual future DFGs in terms of their arc weights (measured as deviations or errors), as well as whether they are capable of reproducing the same process model behaviour (measured against the behaviour of the baseline actual DFG).
This is done at various parts of the trace, i.e. forecasts for the middle of the event logs up to the later parts of the event log to capture the robustness of the forecasting techniques in terms of the amount of data required to obtain good prediction results.
This is done for both the equisized and equitemporal aggregation.

\subsection{Re-sampling and test setup}
In order to obtain training data, time series are obtained by specifying a number of intervals (i.e. time steps in the DF time series) using either equitemporal or equisize aggregation a described in Section \ref{sec:preliminaries}.
Time series algorithms are parametric and sensitive to sample size requirements \cite{hanke2001business}.
Depending on the number of parameters a model uses, a minimum size of at least 50 steps is not uncommon, although typically model performance should be monitored at a varying number of steps.
In the experimental evaluation, the event logs are divided into 100 time steps with a varying share of training and test steps:. A constant and long horizon $h=25$ is used meaning all test sets contain 25 intervals, but the training sets are varied from $ts=25$ to $ts=75$ steps, meaning the forecasts progressively target the prediction of steps 25-50 (the second quarter of intervals) over to 75-100 (the last quarter of intervals).
This allows to both inspect the difference in results when only few data points are used, and whether there is a difference forecasting data points in the middle or towards the end of the available event data.

Resampling is applied based on a 10-fold cross-validation constructed following a rolling window approach for all horizon values $h\in[1,25]$ where a recursive strategy is used to iteratively obtain $\hat{y}_{t+h|T_{t+h-1}}$ with $(y_1,\dots,y_{T},\dots,\hat{y}_{t+h-1})$ \cite{weigend2018time}.
10 training sets are hence constructed for each training set length $ts$ and exist from $(y_1,\dots,y_{T-h-f})$ and the test sets from $(y_{T-h-f+1},\dots,y_{T-f})$ with $f\in[0,9]$ the fold index \cite{bergmeir2012use}.
While direct strategies with a separate model for every value of $h$ can be used as well and avoid the accumulation of error, they do not take into account statistical dependencies for subsequent predictions.

Three widely-used event logs are used: the 2012 BPI challenge log\footnote{\url{https://doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f}}, the Sepsis cases event log\footnote{\url{https://doi.org/10.4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460}}, and the Road Traffic Fine Management Process log (RTFMP) event log (see Section \ref{sec:2:motivation}.
Each of these logs has a diverse set of characteristics in terms of case and activity volume, as well as average trace length as can be seen in Table \ref{tab:eventlogs}.
\begin{table}[htbp]
  \centering
    \begin{tabular}{lrrr}
    \toprule
    \textbf{Event log} & \multicolumn{1}{l}{\textbf{\# cases}} & \multicolumn{1}{l}{\textbf{\# activities}} & \multicolumn{1}{l}{\textbf{Average trace length}} \\
    \midrule
    \textbf{BPI 12} & 13,087 & 36    & 20.020 \\
    \textbf{Sepsis} & 1,050 & 16    & 14.490 \\
    \textbf{RTFMP} & 150,370 & 11    & 3.734 \\
    \bottomrule
    \end{tabular}%
  \caption{Overview of the characteristics of the event logs used in the experimental evaluation.}
  \label{tab:eventlogs}%
\end{table}%

An example of applying the equisize or equitemporal aggregation to the Sepsis event log with 100 intervals results in the DF time series of Figure \ref{fig:sepsists} where the DF occurrences of the most frequently occurring activity pair is included.
For the equisized aggregation the number of DFs is indeed relatively stable over the log's timeline where for the equitemporal aggregation a noticeable decline of DF pairs is visible towards the end of the series.
This phenomenon is typical in event logs, as processes typically have particular endpoint activities, but can also be due to the unequal distribution of events over the event log's time line.
If the level of occurrences of the DF pair is low and close to 0, the series might be too unsuitable for analysis with white noise series analysis techniques that assume stationarity.
Ideally, every time series is tested using a stationarity test such as the Dickey-Fuller unit root test \cite{leybourne1995testing} and an appropriate lag order is established for differencing. 
Furthermore for each algorithm, especially ARIMA-based models, (partial) auto-correlation could establish the ideal $p$ and $q$ parameters.
However, for the sake of simplicity and to avoid solutions where each activity pair has to have different parameters, various values are used for $p$, $d$, and $q$ and applied to all DF pairs where only the best-performing are reported below for comparison with the other time series techniques.
The results contain the best-performing representative of each forecasting family.
\begin{figure}[tb]
	\centering
	\subfigure[Most common DF - equisize]{\includegraphics[width=0.39\textwidth]{./img/rtfmp_1.png}}
	\subfigure[Most common DF - equitemp]{\includegraphics[width=0.39\textwidth]{./img/rtfmp_1_t.png}}
	\caption{RTFMP}
	\label{fig:sepsists}
\end{figure}

\subsection{Evaluation criteria}
Given that we want to evaluate the capability of the approach to accurately predict the evolution of the process model, the combination of all DF predictions to obtain a global DFG prediction is considered.
The following two criteria are used:
\begin{itemize}
	\item \textbf{Cosine distance:} measures the distance between two vectors and is often used to compare graph distance. This metric is used to compare the DFG's edge weight matrices between the actual and predicted number of DF relations.
	\item \textbf{Entropic relevance:} a measure for stochastic conformance checking computed as the average number of bits required to compress each of the logâ€™s traces based on the structure and information about relative likelihoods provided by the model \cite{DBLP:conf/icpm/PolyvyanyyMG20}.
\end{itemize}
These criteria balance a predictive and structural evaluation of the algorithms and report on both the numeric performance common in a forecasting setting as well as their appropriateness in terms of reproducing a structurally usable process model which allows for the observed process behaviour.
In both cases a lower score is better.
The entropic relevance also allows to compare the adequacy the forecasted DFGs with the actual DFGs.

\subsection{Results}
All pre-processing was done in Python with a combination of \emph{pm4py}\footnote{\url{https://pm4py.fit.fraunhofer.de}} and the \emph{statsmodels} package \cite{seabold2010statsmodels}. 
The code and full results are available here\footnote{\url{https://github.com/JohannesDeSmedt/pmf}}.
Figures \ref{fig:rtfmp_equisize} and \ref{fig:rtfmp_equitemp} contain visualisations of the cosine distance and entropic relevance for the RTFMP log, and Table \ref{tab:result_table} contains the mean absolute percentage error (MAPE) of the actual and forecasted DFGs in terms of entropic relevance.
\input{4b-result_table.tex}

The MAPE results show that many techniques are capable of staying well below the 5\% difference for BPI 12 (except for ARIMA after 50 intervals) with the naive forecasting baseline performing competitively with the slightly outperforming ARIMA(2,1,2) model in some cases.
For the Sepsis dataset, results below the 10\% line can be achieved by many techniques, with GARCH performing best for equisize and Holt-Winters for equitemporal aggregation.
Given the few DF occurrences in the later part of the event log, no results can be produced for the equitemporal aggregation.
Finally, the RTFMP only achieves below 15\% MAPE for the 100 intervals or equitemporal aggregation.
Figures \ref{fig:rtfmp_equisize} and \ref{fig:rtfmp_equitemp} show that GARCH indeed performs well in terms of low entropic relevance, but not cosine distance.
Besides, it shows that most techniques perform similarly in terms of entropic relevance.

Overall, there is no clear forecasting technique that stands out over the whole line, while the naive baseline often performs adequately and GARCH reporting best or close-to-best results in at least half the cases.
The errors are higher when fewer intervals are used for training with 100 intervals ($ts=75$) resulting in the lowest MAPE for all three datasets.
Nevertheless, even for 75 intervals ($ts=50$) the results are closer to the 100 than the 50 interval setup.
It also appears that equitemporal aggregation results is lower forecasting errors when the training set is small.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{img/rtfmp_cosine_small_equisize.png}
    \includegraphics[width=0.8\textwidth]{img/rtfmp_entropic_small_equisize.png}
    \caption{Results for equisize aggregation for the RTFMP event log.}
    \label{fig:rtfmp_equisize}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{img/rtfmp_cosine_small_equitemp.png}
    \includegraphics[width=0.8\textwidth]{img/rtfmp_entropic_small_equitemp.png}
    \caption{Results for equitemporal aggregation for the RTFMP event log.}
    \label{fig:rtfmp_equitemp}
\end{figure}

\subsection{Managerial implications}
Depending on the event log, it is feasible to obtain good (<15\%) to very good (<5\%) forecasting results in terms of the MAPE entropic relevance against actual DFGs.
The experiments do show that the number of intervals used for training vastly impacts results, which is expected given that with 10-fold validation this results in only 15 interval being used for the tenth fold to predict the next 25 intervals.
Given that GARCH models often perform strongly suggests that DF time series benefit from the use of models which allow for a varying level of variance.
This makes sense in an event log context, as activities generating the DF occurrences do not occur uniformly during the execution of a process.

\input{4.5-visualisation}